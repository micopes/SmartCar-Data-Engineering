## [진행내용 13에서 발생](https://github.com/micopes/SmartCar-Data-Engineering/blob/main/%EC%A7%84%ED%96%89%20%EB%82%B4%EC%9A%A9/13_%ED%83%90%EC%83%89%20%EC%A3%BC%EC%A0%9C%20%EC%98%81%EC%97%AD.md)

- 실시간 로그 발생 시키고, 진행 중에 과속 데이터 발생 시 실시간으로 redis에 적재되도록 하였다.

> `redis-cli`
>
> `smembers 20210801`

를 수행하였는데, 과속 시 실시간으로 적재가 되지 않음. 시간이 흐른 후에 적재가 되는데 이 속도가 매우 늦다.

<br><hr>

- 실시간 과속 데이터 적재 파악 및 해결 필요

<hr>

### 다시 수행 
```
2021로 변경해서 실습하였지만 여전히 동일한 결과가 발생.

20210801로 전부 변경해서 실습중인데 계속 20210901의 데이터가 레디스에 올라온다.

20210901의 SmartCarDriverInfo.log를 삭제하고 몇 번이나 처음부터 20210801로 변경하여 실습하고 있는데,

tail -f 명령으로 확인할 수 있는 생성되고 있는 데이터 중에서 과속인 데이터가 아니라, redis에서는 key가 20210901로 계속 생성되고 있음.(tail -f로 확인하고 있는 데이터는 모두 20210801의 데이터)
```
![image](https://user-images.githubusercontent.com/43158502/131251615-a8e77c1c-fe7a-417c-8986-fec07b21573d.png)

- 내 생각) 맨 처음에 20210901로 실행했던 것이 뒤늦게 쌓이고 있는 것이라고 생각하는데( 로그를 삭제해도 redis-cli에 계속 과속데이터가 쌓이기 떄문에),

- 단순히 로그를 삭제하는 것이 아니라 redis에 적재되고 있는 상황 및 대기열을 확인하고 이를 멈추는 작업을 수행하는 방법?

### 알게된 것
- 로그를 삭제해도 redis-cli에 계속 과속데이터가 쌓인다. (그러면 이전에 실행한 것이 뒤늦게 쌓이고 있을 확률이 높다.)


### 해결

### 카프카 확인

- 우선 Kafka의 retention 타임을 1주일에서 10분으로 조정을 했었는지 확인. (CM 홈에서 [Kafka] → [구성]을 선 택하고, 검색어로 “Data Retention Time”를 입력한 후 7일에서 10분으로 수정)

> Kafka의 Topic에 쌓이는 실시간 데이터들의 속도보다, Storm에서 데이터를 빼와 처리하고 Redis로 전송하는 속도가 늦어서 발생한 현상일 수도.. 
> 
> 레디스에 20210901 데이터를 삭제 했더라도 카프카에 아직 20210901 데이터가 Topic에 남아 있었다면, 삭제후에도 해당 데이터를 Storm에서 과속여부를 판단해 레디스로 전송 될 수 있기 때문.

- 이걸 확인해 보려면 kafka-consumer 명령으로 20210901 데이터가 남아 있는지 확인!

> `kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic  --partition 0 --from-beginning`
