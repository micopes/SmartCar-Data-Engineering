# 탐색 주제 영역

- 탐색, 분석, 가공 등의 과정이 반복되는데 이 중 패턴이 있으면 workflow로 자동화.
- 자동화된 workflow가 원천 데이터를 탐색/분석/가공 처리하여 *data mart*로.

1. 스마트카 상태 모니터링 정보
- **managed_smartcar_status_info**
  - smartcar_master_over18, smartcar_status_info
2. 스마트카 운전자 운행기록 정보
- **managed_smartcar_drive_info**
  - smartcar_master_over18, smartcar_drive_info_2
3. 이상 운전 패턴 스마트카 정보
- **managed_smartcar_sympton_info**
  - managed_smartcar_drive_info
4. 긴급점검이 필요한 스마트카 정보
- **managed_smartcar_emergency_check_info**
  - managed_smartcar_status_info
5. 운전자의 차량용품 구매 이력 정보
- **managed_smartcar_item_buylist_info**
  - smartcar_master_over18, smartcar_item_buylist


## 데이터 준비

### 스마트카 상태 정보 데이터 생성

- Flume 활성화(Cloudera Manager)
- 로그 데이터 생성(server02)

```
$ cd /home/pilot-pjt/working
$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20210801 100 &
$ cd /home/pilot-pjt/working/SmartCar
$ ls -ltrh SmartCarStatusInfo_20210801.txt
$ ps -ef | grep smartcar.log
$ kill -9 [PID]
```

- 스마트카 상태 정보 데이터를 Flume의 수집 디렉토리로 옮긴다. **Flume이 수집 작업을 시작한다**.(약 10분 정도 시간 소요)

`$ mv /home/pilot-pjt/working/SmartCar/SmartCarStatusInfo_20210801.txt /home/pilot-pjt/working/car-batch-log/`
- HDFS에 정상적으로 적재되었는지 확인(65MB, 52MB) ( .tmp가 있으면 미완료 상태)

`$ hdfs dfs -ls -R /pilot-pjt/collect/car-batch-log/`


### 스마트카 운전자 운행 로그 데이터 생성 및 확인

- Flume, Kafka, HBase 활성화 (Cloudera Manager)
- Storm, Redis 실행

```
$ service storm-nimbus start
$ service storm-supervisor start
$ service storm-ui start
$ service redis_6379 status
```

- 운전자 운행 로그 생성

```
$ cd /home/pilot-pjt/working
$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20210801 100 &
```

- /home/pilot-pjt/working/driver-realtime-log 에 SmartCarDriverInfo.log 파일이 생성된다. 
  - 24시간 기준으로 지속적으로 생성. 
  - tail 명령어로 확인 가능

```
$ cd /home/pilot-pjt/working/driver-realtime-log
$ tail -f SmartCarDriverInfo.log

$ redis-cli
$ 127.0.0.1:6379> smembers 20210801
```

- 3개 이상 과속 데이터 생성되면 종료

```
$ ps -ef | grep smartcar.log
$ kill -9 [PID] [PID]
```

- HBase > DriverCarInfo(Table 명) 에서 00000010901202 (20210901000000을 역으로) 을 이용해서 실시간 자료 확인 가능

- 완료 후 수집/적재 기능 정지
  - Flume
  - Kafka
  - Storm
  - Redis
  - HBase

