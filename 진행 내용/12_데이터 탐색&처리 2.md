# 데이터 탐색 & 처리 2

## HBase 

> Flume, Kafka 등을 활용하여 수집한 것을 적재하는 것이 아니라, 원천 데이터를 수집하고자 할 때. *Hue를 통해 HDFS에 업로드하고 HDFS에 업로드한 파일에 Query 처리할 수 있다.*

- car-master directory
  - carmaster.txt: 차량 주인 정보 내용
- buy-list directory
  - carItemBuyList.txt: 차량 평가 정보 내용

> 두 directory에 각각 .txt 파일 넣고, Hive SQL로 탐색 및 처리한다.

- car-master query

```
create external table smartcar_master (
car_number string,
sex string,
age string,
marriage string,
region string,
job string,
car_capacity string,
car_year string,
car_model string
)
row format delimited
fields terminated by '|'
stored as textfile
location '/pilot-pjt/collect/car-master';
```

- buy-list query

```
create external table smartcar_item_buylist (
car_number string,
Item string,
score string,
month string
)

row format delimited
fields terminated by ','
stored as textfile
location '/pilot-pjt/collect/buy-list';

select * from smartcar_item_buylist limit 10;
```

## Spark
